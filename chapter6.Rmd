---
title: "chapter6"
author: "kiirasar"
date: "2022-12-05"
output: html_document
---


```{r}
date()
```

# Assignment 6: Tasks and Instructions

## Data wrangling **(max 5 points)**

See [meet_and_repeat.R](https://github.com/kiirasar/IODS-project/blob/master/meet_and_repeat.R).

## Analysis **(max 15 points)**

- Use the corresponding **Exercise Set** and the **MABS4IODS** materials
- **Note.** As you read the data sets in your **chapter6.Rmd** you may have to factor the **categorical variables** again, as R may not recognise them automatically as factors.
- **Note.** that you must SWAP the data sets! :) It is NOT a simple copy & paste of the MABS book!

```{r}
#install.packages('ggplot2')
library(dplyr)
library(tidyr)
library(ggplot2)
```

## RATS data and Chapter8 **(0-7 points)**

Implement the analyses of **Chapter 8** of MABS using the **RATS data.** 

- 0-4 points for graphs or analysis results
- 0-3 points for their interpretations

**Download and convert the data to long form**
```{r}
RATS3 <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/rats.txt", header = TRUE, sep = '\t') 
RATS3$ID <- factor(RATS3$ID) #change these to factors
RATS3$Group <- factor(RATS3$Group) #change these to factors

RATSL3 <-  pivot_longer(RATS3, cols = -c(ID, Group),
                       names_to = "WD", values_to = "Weight") %>%
  mutate(Time3 = as.integer(substr(WD,3,4))) %>%
  arrange(Time3) #change it to long-form

glimpse(RATSL3) #sanity-check
```

### Summary RATS
```{r}
names(RATSL3) #"ID"     "Group"  "WD"     "Weight" "Time3" 
str(RATSL3) #176 observations and 5 columns (variables)
summary(RATSL3) #ID and Group factors, WD chr and Weight and Time3 int
```

### Individuals on the plot

Graphical displays of individual datapoint: Weight values over time between 3 groups.
```{r}
library(dplyr); library(tidyr)
ggplot(RATSL3, aes(x = Time3, y = Weight, linetype = ID)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ Group, labeller = label_both) +
  theme(legend.position = "none") + 
  scale_y_continuous(limits = c(min(RATSL3$Weight), max(RATSL3$Weight)))
```

**Interpretation of the plot: Individual plot**
- First, in almost every group the weight is increasing over time (but in group 1 it remains quite stable). 
- Second, Group 2 and 3 have higher weight than group 1 
- Third, there is not much change in weight within the groups. 

### The Golden Standardise - tracking

*"The tracking phenomenon can be seen more clearly in a plot of the standardized values of each
observation, i.e., the values obtained by subtracting the relevant occasion mean from the original observation and then dividing by the corresponding visit standard deviation."* (Exercise6.Rmd)

```{r}
library(dplyr); library(tidyr); library(ggplot2)

#standardize Weight
RATSL3 <- RATSL3 %>%
  group_by(Time3) %>%
  mutate(stdWeight = Weight) %>%
  ungroup()
glimpse(RATSL3) # sanity-check; stdWeight added

# Plot again with the standardised Weight
ggplot(RATSL3, aes(x = Time3, y = stdWeight, linetype = ID)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ Group, labeller = label_both) +
  scale_y_continuous(name = "standardized Weight")
```

**Interpretation of the plot - individual (standardized)**

Since weight is often normally distributed it did not change our results. To double-check this we can use identical() command.

```{r}
identical(RATSL3$Weight, RATSL3$stdWeight) #TRUE
```

### Summary graphs

With large numbers of observations, graphical displays of individual response profiles are of little use and investigators then commonly produce graphs showing average (mean) profiles for each treatment group along with some indication of the variation of the observations at each time point, in this case the standard error of mean

```{r}
library(dplyr); library(tidyr); library(ggplot2)

RATSL3SS <- RATSL3 %>%
  group_by(Group, Time3) %>%
  summarise( mean = Weight, se = Weight ) %>%
  ungroup()
glimpse(RATSL3SS) #sanity-check, means and se added

ggplot(RATSL3SS, aes(x = Time3, y = mean, linetype = Group, shape = Group)) +
  geom_line() +
  scale_linetype_manual(values = c(1,2,3)) +
  geom_point(size=3) +
  scale_shape_manual(values = c(1,2,3)) +
  #geom_errorbar(aes(ymin=mean-se, ymax=mean+se, linetype="1"), width=0.3) +
  theme(legend.position = c(0.9,0.4)) + #change the legend poistion
  scale_y_continuous(name = "mean(Weight) +/- se(Weight)")

ggplot(RATSL3SS, aes(x = Time3, y = mean, linetype = Group, shape = Group)) +
  geom_line() +
  scale_linetype_manual(values = c(1,2,3)) +
  geom_point(size=3) +
  scale_shape_manual(values = c(1,2,3)) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se, linetype="1"), width=0.3) +
  theme(legend.position = c(0.9,0.8)) + #change the legend poistion
  scale_y_continuous(name = "mean(Weight) +/- se(Weight)")

```

**Interpretation of the plot - summary graphs**

These two plots are identical, the last one just have error bars added. Here you can see that

- Group3 (circle) has the lowest average weight in comaprison to group2 and group3, and that the weight stays quite stabel over the time period.
- Group2 (triangle) has similar weight pattern to group3 (cross). The weight seem to go up and down based on different time points.
- The change in weight seem to be greater for group2 than group3
- when counting the error bars it seem that there is quite a lot of variability within the groups.

### Outliers

Create a summary data by treatment and subject with mean as the summary variable and draw a boxplot to investigate the outliers and delete them, if any.

```{r}
library(dplyr); library(tidyr); library(ggplot2)

RATSL3S <- RATSL3 %>%
  group_by(Group, ID) %>%
  summarise( mean=mean(Weight) ) %>%
  ungroup()
glimpse(RATSL3S) #sanity-check

# Draw a boxplot of the mean versus Group
ggplot(RATSL3S, aes(x = Group, y = mean)) +
  geom_boxplot() +
  stat_summary(fun = "mean", geom = "point", shape=23, size=4, fill = "white") +
  scale_y_continuous(name = "mean(Weight), Time 1-64") +
  ylim(200, 600)
```

**Interpretation of the plot - outliers**

It seems that each group has an outlier. To get rid of them I found this useful [link](https://stackoverflow.com/questions/57524258/filter-different-groups-by-different-factor-levels). See **case_when**

- Group1 has an outlier mean weight (min 1 = 237.6)
- Group2 has an outlier mean weight (max 2 = 590.5)
- Group3 has an outlier mean weight (min 3 = 492.9)
- See tapply commands below

```{r}
RATSL3S <- RATSL3 %>%
  group_by(Group, ID) %>%
  summarise( mean=mean(Weight) ) %>%
  ungroup()
glimpse(RATSL3S) #sanity-check

tapply(RATSL3S$mean, RATSL3S$Group, min) # 1=237.6, 2=440.8, 3=492.9
tapply(RATSL3S$mean, RATSL3S$Group, max) # 1=274.7, 2=590.5, 3=540.2

RATSL3S_filter = RATSL3S %>% 
 filter(case_when(Group=="1"~ mean>238,
                  Group=="2"~ mean<590,
                  Group=="3"~ mean>493))

ggplot(RATSL3S_filter, aes(x = Group, y = mean)) +
  geom_boxplot() +
  stat_summary(fun = "mean", geom = "point", shape=23, size=4, fill = "white") +
  scale_y_continuous(name = "mean(Weight), Time 1-64") +
  ylim(200, 600)
```

**Interpretation of the plot - outliers2**

Now the outliers are deleted. Also, the shapes of the boxplots have changed, since we deleted the outliers that also impacted on the quartilies and means. Group 1 has the lowest average weight, followed by Group2 and Group3. Below you can see the comparison between the datasets.

```{r}
tapply(RATSL3S$mean, RATSL3S$Group, summary)
tapply(RATSL3S_filter$mean, RATSL3S_filter$Group, summary)
```

### T-test and Anova

We use data without outliers (RATSL3S_filter). The t-test is used when you compare means of 2 groups and ANOVA two or more groups. Since RATS has 3 groups, we can **a)** conduct ANOVA, or **b)** choose two groups that we compare. 

**ANOVA**
```{r}
#one way
oneway.test(mean ~ Group, data = RATSL3S_filter, var.equal = TRUE)
#another way
res_aov <- aov(mean ~ Group, data = RATSL3S_filter)
summary(res_aov)
```

ANOVAS p-value is 2.721e-14, which is p<.05, meaning there is difference in mean weight between the groups. Next, we need to run Post-Hoc tests, to see where excatly the difference is located. 

T-test can be used as a Post-Hoc test (all tehe other tests have similar idea). But to overcome the problem of multiple comparison, we need to multiply the p-value based on the number of comparisons to see if it still stands. Other option is to divide our chosen p-value (p<.05) by the number of comparison to see what the true acceptable p-value would be (0.05/3=0.01666667). So, the acceptable p-value instead of p<.05 it actually is p<.02.

For conducting t-tests, again, I got some help from [Stackoverflow](https://stackoverflow.com/questions/27930881/r-doing-t-test-between-pairs-of-factors)

**Two-sample t-test**
```{r}
t.test(mean ~ Group, data=RATSL3S_filter[RATSL3S_filter$Group %in% c(1,2),]) #Group 1 and 2
t.test(mean ~ Group, data=RATSL3S_filter[RATSL3S_filter$Group %in% c(1,3),]) #Group 1 and 3
t.test(mean ~ Group, data=RATSL3S_filter[RATSL3S_filter$Group %in% c(2,3),]) #Group 2 and 3
```

There are statistically **significant (p<.05)** difference between 

- Group 1 and 2, p-value = 3.259e-05 = 3.259e-05*3 = 9.777e-05
- Group 1 and 3, p-value = 3.95e-12 = 3.95e-12*3 = 1.185e-11
- Group 2 and 3, p-value = 0.0006444 = 0.0006444*3 = 0.0019332

Since the p-values for the current comparisons are so low, even multiplying them with number of comparison (n=3), they stay statistically significant.

** Fit the linear model** 

```{r}
library(dplyr); library(tidyr)

# Add the baseline from the original data as a new variable to the summary data
RATSL3S_2 <- RATSL3S %>% #use the data without filters, otherwise the dimensions does nto match
  mutate(baseline = RATS3$WD1) #use WD1 as a baseline
glimpse(RATSL3S_2) #sanity-check baseline has been added to the dataframe

fit <- lm(mean~Group+baseline, data = RATSL3S_2) # Fit the linear model with the mean as the response and group and WD1 (baseline) as indicators
anova(fit) # Compute the analysis of variance table for the fitted model with anova()
```

Both **group** and **baseline** are significant in this model (p<.001). Meaning that there are significant difference between the groups at WD1 in weight. So, even at the start of the testing, groups differed based on weight. 

------------------------------------------------------------------------------------------------------------------------------------------------

## BPRS data

Implement the analyses of **Chapter 9 of MABS** using the **BPRS** data. **(0-8 points)**

- 0-4 points for graphs or analysis results
- 0-4 points for their interpretations

**Download and convert the data to long form**
```{r}
BPRS3 <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/BPRS.txt", sep =" ", header = T)

BPRS3$treatment <- factor(BPRS3$treatment)
BPRS3$subject <- factor(BPRS3$subject)

BPRSL3 <-  pivot_longer(BPRS3, cols = -c(treatment, subject),
                       names_to = "weeks", values_to = "bprs3") %>%
  arrange(weeks)

```

```{r}
BPRSL3 <-  BPRSL3 %>% 
            mutate(week = as.integer(substr(weeks,5,5)))
glimpse(BPRS3)
glimpse(BPRSL3)
```

- the original dataset (wide) had 40 rows and 11 columns
- the long version has 360 rows and 6 columns

**Same as above, but standardized**

*BPRSL standardized*
```{r}
BPRSL3_std <- BPRSL3 %>%
  group_by(week) %>%
  mutate(stdbprs = (bprs3 - mean(bprs3))/sd(bprs3) ) %>%
  ungroup()
glimpse(BPRSL3_std) #sanity check, stdbprs
View(BPRSL3_std)
```

### Linear Mixed Effects Models

Lets make a plot where we compare subjects in treatment 1 and 2. I could figure out, how to draw similar plot than in the [MABS4IODS.pdf, Figure 9.2, page 177](https://moodle.helsinki.fi/pluginfile.php/4095603/course/section/599778/MABS4IODS.pdf). 

I think we should have re-name the subjects based on the groups, since now both treatment 1 and 2 have subject 1 etc., that makes it hard to draw them into same plot. Maybe if treatment 1 would have subjects from 1 to 20 and treatment 2 21-40, it might work.

**Plot 1**
```{r}
dim(BPRSL3_std) #360 rows (observations), 6 columns (variables)

# unstandardized
ggplot(BPRSL3_std, aes(x = week, y = bprs3, group = subject, colour=subject)) +
  geom_line() +
  facet_grid(. ~ treatment, labeller = label_both) +
  scale_x_continuous(name = "Weeks") +
  scale_y_continuous(name = "bprs") +
  theme(legend.position = "top")

# standardized
ggplot(BPRSL3_std, aes(x = week, y = stdbprs, group = subject, colour=subject)) +
  geom_line() +
  facet_grid(. ~ treatment, labeller = label_both) +
  scale_x_continuous(name = "Weeks") +
  scale_y_continuous(name = "bprs") +
  theme(legend.position = "top")
```

**Interpretation of Plot 1**

- the first plot is based on non-standardized values and the latter using standardized values.
- Treatment group 2 has one subject (possible outlier) with higher bprs values than other subjects
- Treatment 1 the variability in bprs seem to decrease within time, whereas in Treatment 2 the differences are greater in week 8 (or at least there are more subjects with higher bprs values)


### Holding on to independence: The Linear model

Create a multiple linear regression model with

- bprs values as dependent
- week and treatment as explanatory variables.
- there is no need to use standardized values, since we use bprs as dependent. Unless you are interested in to investigate the variance explained based on standardized bprs values (based on mean). 

```{r}
BPRSL3_reg <- lm(BPRSL3_std$bprs3 ~ BPRSL3_std$week + BPRSL3_std$treatment) #stdbprs as dependent and week and treatment independent variables.
summary(BPRSL3_reg) # summary of the model
```

**Interpretation of the model**

When using **un-standardized** bprs values we see that 

- The average bprs value is 46.45 (intercept, beta-value, starting point)
- The bprs values decreases throughout time. Negative estimate.
- Week is significant predictor to explain the variance in bprs values. p-value is smaller than p<.05.
- Treatment2 is associated having larger bprs values. Positive estimate.
- However, Treatment is not significant, p-value is greater than .05 (p=.661). Treatment group does not explain the variance in bprs groups. In other words, there is no significant difference in bprs based on treatments 


### The Random Intercept Model

The previous model we assumed independence of the repeated measures of bprs, which is very unlikely. Next we will consider that the relationship is dependent (within-subject).

First we will fit the *random intercept model* for the same two explanatory variables: `week` and `treatment`. Fitting a random intercept model allows the linear regression fit for each subject to differ in *intercept* from other subjects (within-subject desing). In otherword, we are interested to investigate how the bprs values change within subjects, and id treatment groups and time variables are playing role in individual changes. 

We use **`lme4` package** which offers efficient tools for fitting linear and generalized linear mixed-effects models. 

The first argument is the `formula` object describing both the fixed-effects and random effects part of the model, with the response on the left of a ~ operator and the terms, separated by + operators, on the right. Note the random-effects terms distinguished by vertical bars (|).
**Note:** You should first install the package `lme4`.


```{r}
#install.packages("lme4")
library(lme4)
BPRSL3_std_ref <- lmer(bprs3 ~ week + treatment + (1 | subject), data = BPRSL3_std, REML = FALSE)
summary(BPRSL3_std_ref) # Print the summary of the model
```

**Interpretation of the model**

Interpretation of t-values see [link](https://home.csulb.edu/~msaintg/ppa696/696stsig.htm#:~:text=A%20t%2Dscore%20must%20fall,relationship%20between%20the%20two%20variables.)

- For a one-tailed test of t, with df=533 and p=.05, t must equal or exceed 1.645.
- For a two-tailed test of t, with df=533 and p=.05, t must equal or exceed 1.960.

The results seem to be very similar when taking into account the random intercept model. Based on the model's estimates and t-values we can conclude:

- week is significant variable (t-value > 1.960)
- the bprs values decreases over time
- treatment is not significant (small t-value t.value < 1.960)
- treatment 2 has a bit higher bprs values in comparison to treatment 1, but this is not significant


### Slippery slopes: Random Intercept and Random Slope Model

Next, fit the *random intercept and random slope model* to the bprs data. "Fitting a random intercept and random slope model allows the linear regression fits for each individual to differ in intercept but also in slope. This way it is possible to account for the individual differences, but also the effect of time." (Exercise6.Rmd)

```{r}
BPRSL3_std_ref2 <- lmer(bprs3 ~ week + treatment + (week | subject), data = BPRSL3_std, REML = FALSE)
summary(BPRSL3_std_ref2) # Print the summary of the model
```

**Interpretation of the model**

- adding slopes decrease the significany of the indicators (week, treatment), but the same results maintain. 
- week is significant (t-value > 1.960) and is associated with reduced bprs values over time
- treatement is not significant (t-value < 1.960), even though treatment2 has higher bprs values.

**Use ANOVA to compare these two models:**

- Compute the analysis of variance tables of the models `BPRSL3_std__ref` and `BPRSL3_std__ref2`
- Pay attention to the chi-squared statistics and p-value of the likelihood ratio test between models. The lower the value the better the fit against the comparison model.

```{r}
anova(BPRSL3_std_ref, BPRSL3_std_ref2)
```

**Interpretation of ANOVA**

- adding slope will increase the model fit significantly (p<.05). 


### Time to interact: Random Intercept and Random Slope Model with interaction

Last, fit a random intercept and slope model that allows for a group × time interaction.

```{r}
BPRSL3_std_ref3 <- lmer(bprs3 ~ week + treatment + week*treatment + (week | subject), data = BPRSL3_std, REML = FALSE)
summary(BPRSL3_std_ref3)
```

**Interpretation of the model**

- adding interaction decrease the significany of the indicators (week, treatment) again. But the same results maintain. 
- week is significant (t-value > 1.960) and is associated with reduced bprs values over time
- treatment is not significant (t-value < 1.960).
- interaction between tretment ad time is not significant (t-value < 1.960). Meaning there are no difference in bprs values between treatment groups based on time interval.


**ANOVA and plot**

perform an ANOVA test on the two previous models (with and without interaction) and draw a plot.

```{r}
anova(BPRSL3_std_ref2, BPRSL3_std_ref3)
```

**Interpretation of ANOVA**

- adding interaction will not the model fit significantly (p<.1). The original model with slope is good-enough to explain the phenomena.

Finally, we will draw a plot based on observed BPRSL3 values and fitted values.


- Draw the plot of *observed* values of RATSL (this is the same plot drawn earlier)
- Create a vector of the fitted values of the model using the function `fitted()`
- Use for example `mutate()` to add the vector `Fitted` as a new column to RATSL
- Draw the plot of *fitted* values of RATSL

Hints:
- Create a vector of the fitted values of the model using the function `fitted()`. Supply it with the model `RATS_ref2`
- Use `mutate()` to add the vector `Fitted` as a new column to RATSL.

```{r}
Fitted <- fitted(BPRSL3_std_ref2) # Create a vector of the fitted values
BPRSL3$Fitted <- Fitted # add Fitted to BPRSL3 data frame
glimpse(BPRSL3) #sanity check
```

**Plots**
```{r}
ggplot(BPRSL3, aes(x = week, y = bprs3, group = subject, colour=subject)) +
  geom_line() +
  facet_grid(. ~ treatment, labeller = label_both) +
  scale_x_continuous(name = "Weeks") +
  scale_y_continuous(name = "bprs") +
  theme(legend.position = "top")

# draw the plot of BPRSL3 with the Fitted values of weight
ggplot(BPRSL3, aes(x = week, y = Fitted, group = subject, colour=subject)) +
  geom_line() +
  facet_grid(. ~ treatment, labeller = label_both) +
  scale_x_continuous(name = "Weeks") +
  scale_y_continuous(name = "bprs fitted") +
  theme(legend.position = "top")
```

**Interpretation of plots**

- first plot is the same as at the start of the assignment
- second plot is fit fitted models. You can see that bprs values goes down within time in both treatment groups. They are very similar, bit Treatment 2 has slightly higher bprs values. 


End of Assignment 6.

Thank you for the course!